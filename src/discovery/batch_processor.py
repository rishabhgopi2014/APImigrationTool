"""
Batch Discovery Processor

Handles parallel discovery of 1500+ APIs with:
- Concurrent processing
- Rate limiting per platform
- Progress tracking
- Error handling and retry logic
- Result caching
"""

import asyncio
import time
from typing import List, Dict, Any, Optional, Callable
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from tqdm import tqdm
from tenacity import retry, stop_after_attempt, wait_exponential

from ..connectors.base import PlatformConnector, DiscoveredAPI
from ..config.filter_engine import FilterEngine, APIMetadata


@dataclass
class BatchDiscoveryResult:
    """Result of batch discovery operation"""
    platform: str
    total_discovered: int
    filtered_count: int
    apis: List[DiscoveredAPI]
    errors: List[str]
    duration_seconds: float
    success: bool


class BatchProcessor:
    """
    Batch processor for discovering 1500+ APIs in parallel.
    
    Features:
    - Concurrent discovery across multiple platforms
    - Per-platform rate limiting
    - Progress bars for user feedback
    - Automatic retry on transient failures
    - Result caching in Redis
    """
    
    def __init__(
        self,
        connectors: Dict[str, PlatformConnector],
        filter_engine: Optional[FilterEngine] = None,
        max_workers: int = 5,
        cache_manager: Optional[Any] = None
    ):
        """
        Initialize batch processor.
        
        Args:
            connectors: Dict of platform_name -> connector
            filter_engine: Filter for selective discovery
            max_workers: Max concurrent discovery workers
            cache_manager: Redis cache manager (optional)
        """
        self.connectors = connectors
        self.filter_engine = filter_engine
        self.max_workers = max_workers
        self.cache = cache_manager
    
    def discover_all(
        self,
        show_progress: bool = True,
        use_cache: bool = True
    ) -> Dict[str, BatchDiscoveryResult]:
        """
        Discover APIs from all configured platforms in parallel.
        
        Args:
            show_progress: Show progress bars
            use_cache: Use cached results if available
            
        Returns:
            Dict of platform_name -> BatchDiscoveryResult
        """
        results = {}
        
        print(f"\nðŸ” Starting API discovery across {len(self.connectors)} platforms...")
        print(f"   Max parallel workers: {self.max_workers}")
        
        # Use ThreadPoolExecutor for concurrent discovery
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit discovery tasks
            future_to_platform = {
                executor.submit(
                    self._discover_platform,
                    platform_name,
                    connector,
                    use_cache
                ): platform_name
                for platform_name, connector in self.connectors.items()
            }
            
            # Collect results with progress tracking
            if show_progress:
                futures = tqdm(
                    as_completed(future_to_platform),
                    total=len(future_to_platform),
                    desc="Discovering APIs",
                    unit="platform"
                )
            else:
                futures = as_completed(future_to_platform)
            
            for future in futures:
                platform_name = future_to_platform[future]
                try:
                    result = future.result()
                    results[platform_name] = result
                    
                    if show_progress:
                        print(f"âœ“ {platform_name}: {result.filtered_count} APIs "
                              f"(discovered {result.total_discovered}, "
                              f"filtered to {result.filtered_count})")
                        
                except Exception as e:
                    print(f"âœ— {platform_name}: Discovery failed - {e}")
                    results[platform_name] = BatchDiscoveryResult(
                        platform=platform_name,
                        total_discovered=0,
                        filtered_count=0,
                        apis=[],
                        errors=[str(e)],
                        duration_seconds=0,
                        success=False
                    )
        
        # Summary
        total_apis = sum(r.filtered_count for r in results.values())
        successful_platforms = sum(1 for r in results.values() if r.success)
        
        print(f"\nâœ¨ Discovery Summary:")
        print(f"   Total APIs discovered: {total_apis}")
        print(f"   Platforms succeeded: {successful_platforms}/{len(self.connectors)}")
        
        return results
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    def _discover_platform(
        self,
        platform_name: str,
        connector: PlatformConnector,
        use_cache: bool = True
    ) -> BatchDiscoveryResult:
        """
        Discover APIs from a single platform with retry logic.
        
        Args:
            platform_name: Platform identifier
            connector: Platform connector
            use_cache: Use cached results
            
        Returns:
            BatchDiscoveryResult
        """
        start_time = time.time()
        errors = []
        
        try:
            # Check cache first
            if use_cache and self.cache:
                cached_result = self._get_cached_result(platform_name)
                if cached_result:
                    print(f"ðŸ“¦ Using cached results for {platform_name}")
                    return cached_result
            
            # Connect to platform
            try:
                connector.connect()
            except Exception as e:
                errors.append(f"Connection failed: {e}")
                raise
            
            # Discover APIs
            try:
                discovered_apis = connector.discover_apis()
            except Exception as e:
                errors.append(f"Discovery failed: {e}")
                raise
            
            # Apply filters
            filtered_apis = discovered_apis
            if self.filter_engine:
                # Convert to APIMetadata for filtering
                api_metadata = [
                    APIMetadata(
                        name=api.name,
                        platform=api.platform,
                        tags=api.tags,
                        owner_team=api.owner_team,
                        owner_domain=api.owner_domain,
                        path=api.base_path
                    )
                    for api in discovered_apis
                ]
                
                # Filter
                filtered_metadata = self.filter_engine.filter(api_metadata)
                filtered_names = {meta.name for meta in filtered_metadata}
                
                filtered_apis = [
                    api for api in discovered_apis
                    if api.name in filtered_names
                ]
            
            duration = time.time() - start_time
            
            result = BatchDiscoveryResult(
                platform=platform_name,
                total_discovered=len(discovered_apis),
                filtered_count=len(filtered_apis),
                apis=filtered_apis,
                errors=errors,
                duration_seconds=duration,
                success=True
            )
            
            # Cache result
            if self.cache:
                self._cache_result(platform_name, result)
            
            return result
            
        except Exception as e:
            duration = time.time() - start_time
            return BatchDiscoveryResult(
                platform=platform_name,
                total_discovered=0,
                filtered_count=0,
                apis=[],
                errors=errors + [str(e)],
                duration_seconds=duration,
                success=False
            )
    
    def _get_cached_result(self, platform_name: str) -> Optional[BatchDiscoveryResult]:
        """Get cached discovery result from Redis"""
        # TODO: Implement Redis cache retrieval
        return None
    
    def _cache_result(self, platform_name: str, result: BatchDiscoveryResult):
        """Cache discovery result in Redis"""
        # TODO: Implement Redis cache storage
        pass
    
    def get_all_apis(self, results: Dict[str, BatchDiscoveryResult]) -> List[DiscoveredAPI]:
        """
        Get all discovered APIs from batch results.
        
        Args:
            results: Discovery results from discover_all()
            
        Returns:
            Flattened list of all discovered APIs
        """
        all_apis = []
        
        for result in results.values():
            if result.success:
                all_apis.extend(result.apis)
        
        return all_apis
    
    def get_statistics(self, results: Dict[str, BatchDiscoveryResult]) -> Dict[str, Any]:
        """
        Get discovery statistics.
        
        Args:
            results: Discovery results
            
        Returns:
            Statistics dict
        """
        total_discovered = sum(r.total_discovered for r in results.values())
        total_filtered = sum(r.filtered_count for r in results.values())
        successful_platforms = sum(1 for r in results.values() if r.success)
        total_duration = sum(r.duration_seconds for r in results.values())
        
        return {
            "total_platforms": len(results),
            "successful_platforms": successful_platforms,
            "total_discovered": total_discovered,
            "total_filtered": total_filtered,
            "filter_reduction_pct": (
                ((total_discovered - total_filtered) / total_discovered * 100)
                if total_discovered > 0 else 0
            ),
            "total_duration_seconds": total_duration,
            "avg_duration_per_platform": total_duration / len(results) if results else 0
        }
